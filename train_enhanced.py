# train_enhanced.py - å¢å¼ºç‰ˆè®­ç»ƒè„šæœ¬ï¼Œæ•´åˆæ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½

import os
import torch
import logging
import argparse
import random
import numpy as np
from torch.utils.data import DataLoader
from transformers import BertTokenizerFast, get_scheduler
from model.bert_crf_model import BertCRF
from model.bert_attention_crf_model import BertAttentionCRF
from utils import NERDataset, get_label_list
from data_augmentation import DataAugmentation, create_sample_dictionaries
from model_optimization import ModelOptimizer
from model_explainability import ModelExplainer
import matplotlib.pyplot as plt
from tqdm import tqdm
from seqeval.metrics import precision_score, recall_score, f1_score, classification_report
from config import model_config, augmentation_config, optimization_config, explainability_config, experiment_config
from datetime import datetime
import json
from model.model_factory import ModelFactory
import multiprocessing
from multiprocessing import freeze_support

def main():
    # å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ä¸­æ–‡åŒ»ç–—NERæ¨¡å‹è®­ç»ƒå·¥å…·')
    parser.add_argument('--pretrained_model', type=str, default=model_config['bert_model_name'], 
                        help='é¢„è®­ç»ƒæ¨¡å‹åç§°ï¼Œå¯é€‰ï¼šbert-base-chinese, chinese-medical-bert, pcl-medbert, cmeee-bert, mc-bert, chinese-roberta-med')
    parser.add_argument('--use_attention', action='store_true', default=model_config.get('use_attention', False), help='æ˜¯å¦ä½¿ç”¨æ³¨æ„åŠ›æ¨¡å‹')
    parser.add_argument('--use_bilstm', action='store_true', default=model_config.get('use_bilstm', False), help='æ˜¯å¦ä½¿ç”¨BiLSTMå±‚')
    parser.add_argument('--no_bilstm', action='store_true', help='ç¦ç”¨BiLSTMå±‚ï¼ˆè¦†ç›–é»˜è®¤é…ç½®ï¼‰')
    parser.add_argument('--batch_size', type=int, default=model_config['batch_size'], help='è®­ç»ƒæ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=model_config['num_epochs'], help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--learning_rate', type=float, default=model_config['learning_rate'], help='å­¦ä¹ ç‡')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--use_augmentation', action='store_true', default=augmentation_config['use_data_augmentation'], help='æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼º')
    parser.add_argument('--no_augmentation', action='store_true', help='ç¦ç”¨æ•°æ®å¢å¼ºï¼ˆè¦†ç›–é»˜è®¤é…ç½®ï¼‰')
    parser.add_argument('--early_stopping', type=int, default=model_config['early_stopping_patience'], help='æ—©åœè€å¿ƒå€¼')
    parser.add_argument('--save_every_epoch', action='store_true', help='æ˜¯å¦æ¯ä¸ªepochä¿å­˜æ¨¡å‹')
    parser.add_argument('--lstm_hidden_size', type=int, default=model_config['lstm_hidden_size'], help='LSTMéšè—å±‚å¤§å°')
    parser.add_argument('--lstm_layers', type=int, default=model_config['lstm_layers'], help='LSTMå±‚æ•°')
    parser.add_argument('--use_model_pruning', action='store_true', default=optimization_config['use_model_pruning'], help='æ˜¯å¦ä½¿ç”¨æ¨¡å‹å‰ªæ')
    parser.add_argument('--use_model_quantization', action='store_true', default=optimization_config['use_model_quantization'], help='æ˜¯å¦ä½¿ç”¨æ¨¡å‹é‡åŒ–')
    args = parser.parse_args()

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(args.seed)
    np.random.seed(args.seed)

    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    batch_size = args.batch_size
    num_epochs = args.epochs
    learning_rate = args.learning_rate
    early_stopping_patience = args.early_stopping
    lstm_hidden_size = args.lstm_hidden_size
    lstm_layers = args.lstm_layers

    # æ³¨æ„ï¼šno_bilstm æ¯” use_bilstm ä¼˜å…ˆçº§é«˜
    use_bilstm = args.use_bilstm
    if args.no_bilstm:
        use_bilstm = False

    # æ³¨æ„ï¼šno_augmentation æ¯” use_augmentation ä¼˜å…ˆçº§é«˜
    use_augmentation = args.use_augmentation
    if args.no_augmentation:
        use_augmentation = False

    # æ¨¡å‹å‰ªæå’Œé‡åŒ–
    use_model_pruning = args.use_model_pruning
    use_model_quantization = args.use_model_quantization

    # è·å–æ¨¡å‹IDç”¨äºæ–‡ä»¶å‘½å
    model_id = args.pretrained_model.replace('-', '_').replace('/', '_')
    model_type = "attention" if args.use_attention else "base"
    bilstm_status = "with_bilstm" if use_bilstm else "no_bilstm"
    aug_status = "augmented" if use_augmentation else "no_aug"
    model_signature = f"{model_id}_{model_type}_{bilstm_status}_{aug_status}"

    # æ£€æµ‹GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("âœ… æ˜¯å¦æ£€æµ‹åˆ° GPU:", torch.cuda.is_available())
    if torch.cuda.is_available():
        print("ğŸ–¥ï¸ å½“å‰ GPU åç§°:", torch.cuda.get_device_name(0))
        print("ğŸ”¥ å½“å‰è®¾å¤‡:", device)
    else:
        print("âŒ å½“å‰ä½¿ç”¨çš„æ˜¯ CPU")

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    # ä¿®å¤è·¯å¾„å¤„ç†ï¼Œé¿å…/è¢«å½“ä½œç›®å½•åˆ†éš”ç¬¦
    safe_model_id = model_id.replace('/', '_')
    results_dir = os.path.join('results', safe_model_id)
    model_dir = os.path.join(model_config['model_dir'], safe_model_id)
    log_dir = os.path.join(model_config['log_dir'], safe_model_id)
    
    # åˆ é™¤é”™è¯¯çš„ç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    wrong_results_dir = os.path.join('results', model_id.split('/')[0])
    wrong_model_dir = os.path.join(model_config['model_dir'], model_id.split('/')[0])
    wrong_log_dir = os.path.join(model_config['log_dir'], model_id.split('/')[0])
    
    # å¦‚æœå­˜åœ¨é”™è¯¯ç›®å½•ä½†æ²¡æœ‰å­å†…å®¹ï¼Œåˆ™åˆ é™¤
    for wrong_dir in [wrong_results_dir, wrong_model_dir, wrong_log_dir]:
        if '/' in model_id and os.path.exists(wrong_dir):
            try:
                # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºç›®å½•
                if not os.listdir(wrong_dir):
                    os.rmdir(wrong_dir)
                    print(f"å·²åˆ é™¤é”™è¯¯åˆ›å»ºçš„ç©ºç›®å½•: {wrong_dir}")
            except:
                pass
    
    os.makedirs(results_dir, exist_ok=True)
    os.makedirs(model_dir, exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(explainability_config['visualization_output_dir'], exist_ok=True)

    # è®¾ç½®æ—¥å¿— - ä½¿ç”¨utf-8ç¼–ç 
    log_filename = f'train_{model_signature}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(os.path.join(log_dir, log_filename), encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    logger = logging.getLogger(__name__)

    # è®°å½•è®­ç»ƒé…ç½®ä¿¡æ¯ - ç§»é™¤emojiä»¥é¿å…ç¼–ç é—®é¢˜
    logger.info("="*50)
    logger.info("åŒ»å­¦å‘½åå®ä½“è¯†åˆ«æ¨¡å‹è®­ç»ƒå¼€å§‹")
    logger.info("="*50)
    logger.info(f"é¢„è®­ç»ƒæ¨¡å‹: {args.pretrained_model}")
    logger.info(f"æ¨¡å‹æ¶æ„: {'BERT-Attention-CRF' if args.use_attention else 'BERT-CRF'}")
    logger.info(f"BiLSTMå±‚: {'å¯ç”¨' if use_bilstm else 'ç¦ç”¨'}")
    if use_bilstm:
        logger.info(f"   - éšè—å±‚å¤§å°: {lstm_hidden_size}")
        logger.info(f"   - LSTMå±‚æ•°: {lstm_layers}")
        logger.info(f"   - ä¸¢å¼ƒç‡: {model_config['lstm_dropout']}")
    logger.info(f"æ•°æ®å¢å¼º: {'å¯ç”¨' if use_augmentation else 'ç¦ç”¨'}")
    logger.info(f"è®­ç»ƒå‚æ•°:")
    logger.info(f"   - æ‰¹æ¬¡å¤§å°: {batch_size}")
    logger.info(f"   - è®­ç»ƒè½®æ•°: {num_epochs}")
    logger.info(f"   - å­¦ä¹ ç‡: {learning_rate}")
    logger.info(f"   - æ—©åœè€å¿ƒå€¼: {early_stopping_patience}")
    logger.info(f"   - æ¯è½®ä¿å­˜: {'å¯ç”¨' if args.save_every_epoch else 'ç¦ç”¨'}")
    logger.info(f"   - æ¨¡å‹å‰ªæ: {'å¯ç”¨' if use_model_pruning else 'ç¦ç”¨'}")
    logger.info(f"   - æ¨¡å‹é‡åŒ–: {'å¯ç”¨' if use_model_quantization else 'ç¦ç”¨'}")
    logger.info(f"æ¨¡å‹ç‰¹å¾ç­¾å: {model_signature}")
    logger.info(f"æ¨¡å‹ç»“æœå­˜å‚¨ä½ç½®: {results_dir}")
    logger.info(f"æ¨¡å‹ä¿å­˜ä½ç½®: {model_dir}")
    logger.info("="*50)

    # æ‰“å°é€‰æ‹©çš„æ¨¡å‹
    print(f"ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: {args.pretrained_model}")
    print(f"æ¨¡å‹ç±»å‹: {'BERT-Attention-CRF' if args.use_attention else 'BERT-CRF'}")
    print(f"BiLSTMå±‚: {'å¯ç”¨' if use_bilstm else 'ç¦ç”¨'}")
    print(f"æ•°æ®å¢å¼º: {'å¯ç”¨' if use_augmentation else 'ç¦ç”¨'}")
    print(f"ç»“æœä¿å­˜ç›®å½•: {results_dir}")
    print(f"æ¨¡å‹ä¿å­˜ç›®å½•: {model_dir}")

    # è·å–å¯ç”¨é¢„è®­ç»ƒæ¨¡å‹åˆ—è¡¨
    available_models = ModelFactory.list_available_models()
    if args.pretrained_model not in available_models:
        logger.warning(f"è­¦å‘Š: æ‰€é€‰æ¨¡å‹ '{args.pretrained_model}' ä¸åœ¨é¢„é…ç½®åˆ—è¡¨ä¸­ã€‚å¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
        logger.warning(f"å°è¯•ç›´æ¥ä»Hugging FaceåŠ è½½æ¨¡å‹...")
        print(f"è­¦å‘Š: æ‰€é€‰æ¨¡å‹ '{args.pretrained_model}' ä¸åœ¨é¢„é…ç½®åˆ—è¡¨ä¸­ã€‚å¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
        print(f"å°è¯•ç›´æ¥ä»Hugging FaceåŠ è½½æ¨¡å‹...")

    # ä½¿ç”¨æ¨¡å‹å·¥å‚è·å–ä¸æ¨¡å‹åŒ¹é…çš„tokenizer
    tokenizer = ModelFactory.get_tokenizer_for_model(args.pretrained_model)

    # æ„å»ºæ ‡ç­¾æ˜ å°„
    label_list = get_label_list([
        model_config['train_path'],
        model_config['dev_path']
    ])
    label2id = {label: i for i, label in enumerate(label_list)}
    id2label = {i: label for label, i in label2id.items()}
    num_labels = len(label_list)

    logger.info(f"æ ‡ç­¾æ€»æ•°: {num_labels}")
    logger.info(f"æ ‡ç­¾åˆ—è¡¨: {label_list}")

    # æ•°æ®å¢å¼º
    if use_augmentation:
        logger.info("æ­£åœ¨å‡†å¤‡æ•°æ®å¢å¼º...")
        
        # æ£€æŸ¥åŒä¹‰è¯å’Œå®ä½“è¯å…¸æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»ºç¤ºä¾‹è¯å…¸
        if not os.path.exists(augmentation_config['synonym_dict_path']) or \
          not os.path.exists(augmentation_config['entity_dict_path']):
            logger.info("æœªæ‰¾åˆ°è¯å…¸æ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹è¯å…¸...")
            create_sample_dictionaries()
        
        # åˆå§‹åŒ–æ•°æ®å¢å¼ºå™¨
        augmenter = DataAugmentation(
            synonym_dict_path=augmentation_config['synonym_dict_path'],
            entity_dict_path=augmentation_config['entity_dict_path']
        )
        
        # è¯»å–åŸå§‹è®­ç»ƒæ•°æ®
        with open(model_config['train_path'], 'r', encoding='utf-8') as f:
            train_data = f.read().strip().split('\n\n')
        
        # å¢å¼ºæ•°æ®
        augmented_data = []
        for sample in tqdm(train_data, desc="æ•°æ®å¢å¼º"):
            if not sample.strip():
                continue
            
            # è§£ææ ·æœ¬
            lines = sample.strip().split('\n')
            words, labels = [], []
            for line in lines:
                if line.strip():
                    parts = line.strip().split()
                    if len(parts) == 2:
                        words.append(parts[0])
                        labels.append(parts[1])
            
            # åº”ç”¨æ•°æ®å¢å¼º
            if random.random() < 0.7:  # åªå¯¹70%çš„æ ·æœ¬è¿›è¡Œå¢å¼º
                aug_words, aug_labels = augmenter.augment_data(
                    words, labels,
                    use_synonym_replace=augmentation_config['use_synonym_replace'],
                    use_entity_replace=augmentation_config['use_entity_replace'],
                    synonym_replace_ratio=augmentation_config['synonym_replace_ratio'],
                    entity_replace_ratio=augmentation_config['entity_replace_ratio']
                )
                
                # æ·»åŠ å¢å¼ºåçš„æ ·æœ¬
                aug_sample = '\n'.join([f"{w}\t{l}" for w, l in zip(aug_words, aug_labels)])
                augmented_data.append(aug_sample)
        
        # åˆå¹¶åŸå§‹æ•°æ®å’Œå¢å¼ºæ•°æ®
        all_data = train_data + augmented_data
        logger.info(f"æ•°æ®å¢å¼ºå®Œæˆ: åŸå§‹æ ·æœ¬æ•° {len(train_data)}, å¢å¼ºåæ ·æœ¬æ•° {len(all_data)}")
        
        # ä¿å­˜å¢å¼ºåçš„æ•°æ®
        augmented_train_path = os.path.join(results_dir, f'train_augmented_{model_signature}.txt')
        with open(augmented_train_path, 'w', encoding='utf-8') as f:
            f.write('\n\n'.join(all_data))
        
        # æ›´æ–°è®­ç»ƒæ•°æ®è·¯å¾„
        train_path = augmented_train_path
    else:
        train_path = model_config['train_path']

    # åŠ è½½æ•°æ®é›†
    train_dataset = NERDataset(train_path, tokenizer, label2id, model_config['max_len'])
    dev_dataset = NERDataset(model_config['dev_path'], tokenizer, label2id, model_config['max_len'])

    # Windowsä¸Šè®¾ç½®num_workers=0ä»¥é¿å…å¤šè¿›ç¨‹é—®é¢˜
    num_workers = 0 if os.name == 'nt' else (4 if torch.cuda.is_available() else 0)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    dev_loader = DataLoader(dev_dataset, batch_size=model_config['eval_batch_size'], num_workers=num_workers)

    # ä½¿ç”¨æ¨¡å‹å·¥å‚åˆ›å»ºæ¨¡å‹
    model = ModelFactory.create_model(
        model_type='bert_attention_crf' if args.use_attention else 'bert_crf',
        num_labels=num_labels,
        pretrained_model_name=args.pretrained_model,
        use_attention=args.use_attention
    )

    # ç¡®ä¿æ¨¡å‹ä½¿ç”¨æ­£ç¡®çš„BiLSTMè®¾ç½®
    if hasattr(model, 'use_bilstm'):
        model.use_bilstm = use_bilstm
    if hasattr(model, 'lstm_hidden_size'):
        model.lstm_hidden_size = lstm_hidden_size
    if hasattr(model, 'lstm_layers'):
        model.lstm_layers = lstm_layers

    model.to(device)

    # æ‰“å°æ¨¡å‹å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    logger.info(f"æ¨¡å‹å‚æ•°: æ€»è®¡ {total_params/1e6:.2f}M, å¯è®­ç»ƒ {trainable_params/1e6:.2f}M")
    print(f"æ¨¡å‹å‚æ•°: æ€»è®¡ {total_params/1e6:.2f}M, å¯è®­ç»ƒ {trainable_params/1e6:.2f}M")

    # åˆå§‹åŒ–æ¨¡å‹ä¼˜åŒ–å™¨
    model_optimizer = ModelOptimizer(model, device)

    # ä¼˜åŒ–å™¨é…ç½®
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=learning_rate,
        weight_decay=model_config['weight_decay']
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå¸¦é¢„çƒ­ï¼‰
    num_training_steps = len(train_loader) * num_epochs
    num_warmup_steps = int(num_training_steps * model_config['warmup_ratio'])
    lr_scheduler = get_scheduler(
        "linear",
        optimizer=optimizer,
        num_warmup_steps=num_warmup_steps,
        num_training_steps=num_training_steps
    )

    # éªŒè¯é›†è¯„ä¼°å‡½æ•°
    def evaluate_on_dev():
        model.eval()
        true_labels = []
        pred_labels = []
        
        with torch.no_grad():
            for batch in tqdm(dev_loader, desc="Evaluating"):
                batch = {k: v.to(device) for k, v in batch.items()}
                pred = model(batch['input_ids'], batch['attention_mask'], batch['token_type_ids'])
                
                # å¤„ç†æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬
                for i in range(batch['input_ids'].size(0)):
                    label_ids = batch['labels'][i].tolist()
                    pred_ids = pred[i]
                    
                    tokens = tokenizer.convert_ids_to_tokens(batch['input_ids'][i])
                    word_labels = []
                    word_preds = []
                    
                    for token, true_id, pred_id in zip(tokens, label_ids, pred_ids):
                        if token in ["[CLS]", "[SEP]", "[PAD]"] or true_id == -100:
                            continue
                        word_labels.append(id2label[true_id])
                        word_preds.append(id2label[pred_id])
                    
                    if word_labels:
                        true_labels.append(word_labels)
                        pred_labels.append(word_preds)

        # è®¡ç®—æ•´ä½“æŒ‡æ ‡
        p = precision_score(true_labels, pred_labels)
        r = recall_score(true_labels, pred_labels)
        f1 = f1_score(true_labels, pred_labels)
        
        # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
        report = classification_report(true_labels, pred_labels, digits=4, output_dict=True)
        
        return p, r, f1, report

    # è®­ç»ƒå¾ªç¯
    logger.info(f"å¼€å§‹è®­ç»ƒ: ä½¿ç”¨ {args.pretrained_model} æ¨¡å‹, {'å¸¦' if args.use_attention else 'ä¸å¸¦'}æ³¨æ„åŠ›, {'ä½¿ç”¨' if use_bilstm else 'ä¸ä½¿ç”¨'}BiLSTM")
    best_f1 = 0
    epoch_metrics = []
    loss_history = []
    f1_history = []
    early_stop_counter = 0
    patience = early_stopping_patience

    print("\nè®­ç»ƒå¼€å§‹...")
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}")
        
        for step, batch in enumerate(progress_bar):
            batch = {k: v.to(device) for k, v in batch.items()}
            loss = model(**batch)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), model_config['max_grad_norm'])
            
            optimizer.step()
            lr_scheduler.step()
            optimizer.zero_grad()
            total_loss += loss.item()
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({'loss': f'{loss.item():.4f}', 'lr': f'{optimizer.param_groups[0]["lr"]:.2e}'})
            
            # å®šæœŸè®°å½•è®­ç»ƒä¿¡æ¯
            if (step + 1) % model_config['logging_steps'] == 0:
                logger.info(
                    f'Epoch: {epoch+1}/{num_epochs}, '
                    f'Step: {step+1}/{len(train_loader)}, '
                    f'Loss: {loss.item():.4f}, '
                    f'LR: {optimizer.param_groups[0]["lr"]:.2e}'
                )

        avg_loss = total_loss / len(train_loader)
        loss_history.append(avg_loss)
        
        # éªŒè¯é›†è¯„ä¼°
        print(f"Epoch {epoch+1}, Train Loss: {avg_loss:.4f}")
        print("æ­£åœ¨éªŒè¯...")
        p, r, f1, report = evaluate_on_dev()
        f1_history.append(f1)
        
        # è®°å½•æœ¬è½®å„å®ä½“ç±»å‹çš„æŒ‡æ ‡
        epoch_result = {
            'epoch': epoch + 1,
            'loss': avg_loss,
            'precision': p,
            'recall': r,
            'f1': f1,
            'entity_metrics': {}
        }
        
        # è®°å½•è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š
        logger.info(f"Epoch {epoch+1} éªŒè¯é›†æŒ‡æ ‡: Precision={p:.4f}, Recall={r:.4f}, F1={f1:.4f}")
        print(f"\tDev Precision: {p:.4f}, Recall: {r:.4f}, F1: {f1:.4f}")
        
        # è®°å½•æ¯ç§å®ä½“ç±»å‹çš„è¯¦ç»†æŒ‡æ ‡
        for entity_type, metrics in report.items():
            if entity_type != "micro avg" and entity_type != "macro avg" and entity_type != "weighted avg" and isinstance(metrics, dict):
                entity_p = metrics['precision']
                entity_r = metrics['recall']
                entity_f1 = metrics['f1-score']
                logger.info(f"å®ä½“ç±»å‹ {entity_type}: P={entity_p:.4f}, R={entity_r:.4f}, F1={entity_f1:.4f}")
                print(f"\tå®ä½“ {entity_type}: P={entity_p:.4f}, R={entity_r:.4f}, F1={entity_f1:.4f}")
                epoch_result['entity_metrics'][entity_type] = {
                    'precision': entity_p,
                    'recall': entity_r,
                    'f1': entity_f1
                }
        
        epoch_metrics.append(epoch_result)
        
        # æ¯è½®ä¿å­˜æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if args.save_every_epoch:
            epoch_model_path = os.path.join(model_dir, f"epoch_{epoch+1}_{model_signature}.pth")
            torch.save(model.state_dict(), epoch_model_path)
            logger.info(f"Epoch {epoch+1} æ¨¡å‹å·²ä¿å­˜è‡³ {epoch_model_path}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if f1 > best_f1:
            best_f1 = f1
            model_save_path = os.path.join(model_dir, f"best_model_{model_signature}.pth")
            torch.save(model.state_dict(), model_save_path)
            print(f"\tæ–°æœ€ä½³æ¨¡å‹ï¼Œå·²ä¿å­˜è‡³ {model_save_path}")
            logger.info(f"æ–°æœ€ä½³æ¨¡å‹ (F1={f1:.4f})ï¼Œå·²ä¿å­˜è‡³ {model_save_path}")
            early_stop_counter = 0
        else:
            early_stop_counter += 1
            print(f"\tæœªæå‡ï¼ŒEarlyStopping è®¡æ•°: {early_stop_counter}/{patience}")
            if early_stop_counter >= patience:
                print("\næå‰åœæ­¢è®­ç»ƒï¼ˆéªŒè¯é›† F1 æ— æå‡ï¼‰")
                logger.info(f"æå‰åœæ­¢è®­ç»ƒ: {early_stop_counter} è½®æœªè§æå‡")
                break

    # ä¿å­˜æœ€åæ¨¡å‹
    final_model_path = os.path.join(model_dir, f"final_model_{model_signature}.pth")
    torch.save(model.state_dict(), final_model_path)
    print(f"\næ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæ¨¡å‹å·²ä¿å­˜è‡³ {final_model_path}")
    logger.info(f"è®­ç»ƒå®Œæˆï¼Œæœ€ç»ˆæ¨¡å‹å·²ä¿å­˜è‡³ {final_model_path}")

    # å¯è§†åŒ–è®­ç»ƒæŸå¤±å’ŒF1
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(range(1, len(loss_history) + 1), loss_history, marker='o')
    plt.xlabel("Epoch")
    plt.ylabel("Average Loss")
    plt.title("Training Loss")
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(range(1, len(f1_history) + 1), f1_history, marker='o', color='orange')
    plt.xlabel("Epoch")
    plt.ylabel("F1 Score")
    plt.title("Validation F1")
    plt.grid(True)

    plt.tight_layout()
    metrics_chart_path = os.path.join(results_dir, f"training_metrics_{model_signature}.png")
    plt.savefig(metrics_chart_path)
    print(f"è®­ç»ƒæŒ‡æ ‡å›¾å·²ä¿å­˜è‡³ {metrics_chart_path}")
    logger.info(f"è®­ç»ƒæŒ‡æ ‡å›¾å·²ä¿å­˜è‡³ {metrics_chart_path}")

    # ä¿å­˜è®­ç»ƒæŒ‡æ ‡è®°å½•
    metrics_json_path = os.path.join(results_dir, f"training_metrics_{model_signature}.json")
    with open(metrics_json_path, 'w', encoding='utf-8') as f:
        json.dump({
            'model_info': {
                'pretrained_model': args.pretrained_model,
                'use_attention': args.use_attention,
                'use_bilstm': use_bilstm,
                'use_augmentation': use_augmentation,
                'batch_size': batch_size,
                'epochs': num_epochs,
                'learning_rate': learning_rate
            },
            'best_f1': best_f1,
            'epochs': epoch_metrics
        }, f, ensure_ascii=False, indent=4)
    logger.info(f"è®­ç»ƒæŒ‡æ ‡è®°å½•å·²ä¿å­˜è‡³ {metrics_json_path}")

    # æ‰“å°æœ€ç»ˆç»“æœ
    print("\nè®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³F1åˆ†æ•°: {best_f1:.4f}")
    print(f"æœ€ä½³æ¨¡å‹è·¯å¾„: {model_save_path}")
    print(f"æœ€ç»ˆæ¨¡å‹è·¯å¾„: {final_model_path}")
    print(f"è¯¦ç»†è®­ç»ƒè®°å½•: {metrics_json_path}")

    # å¦‚æœå¯ç”¨äº†å®éªŒè·Ÿè¸ª
    if experiment_config['use_wandb']:
        try:
            import wandb
            wandb.finish()
        except ImportError:
            logger.warning("æœªå®‰è£…wandbï¼Œæ— æ³•ç»“æŸå®éªŒè·Ÿè¸ªã€‚")
        except Exception as e:
            logger.warning(f"å…³é—­wandbæ—¶å‡ºé”™: {e}")

    print("\nè¯„ä¼°æ¨¡å‹: python evaluate.py --model " + model_save_path + " --pretrained_model " + args.pretrained_model + 
        (" --use_attention" if args.use_attention else "") + (" --use_bilstm" if use_bilstm else ""))

    print("\né¢„æµ‹æ ·ä¾‹: python predict_enhanced.py --model " + model_save_path + " --pretrained_model " + args.pretrained_model + 
        (" --use_attention" if args.use_attention else "") + (" --use_bilstm" if use_bilstm else "") + 
        " --input 'æ‚£è€…å‡ºç°é«˜è¡€å‹å’Œ2å‹ç³–å°¿ç—…ï¼Œå»ºè®®æœç”¨é™å‹è¯ã€‚'")

if __name__ == "__main__":
    # åœ¨Windowsä¸Šä½¿ç”¨å¤šè¿›ç¨‹æ—¶å¿…éœ€
    freeze_support()
    multiprocessing.set_start_method('spawn', force=True)
    main()